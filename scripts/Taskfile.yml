# https://taskfile.dev

version: '3'

vars:
  BLAZEGRAPH_ENDPOINT: http://blazegraph:8080/blazegraph/sparql
  BLAZEGRAPH_ENDPOINT_SECONDARY: http://blazegraph-secondary:8080/blazegraph/sparql
  OAI_ENDPOINT: https://www.e-manuscripta.ch/zuzcmi/oai
  GENERATOR_POLICY: /mapping/generator-policy.xml
  MAPPING_BATCH_SIZE: 10

output: 'prefixed'

tasks:

  default:
    desc: Runs the entire pipeline
    silent: true
    cmds:
      - task: retrieve-data-from-e-manuscripta
      - task: cache-iiif-manifests
      - task: prepare-data-for-mapping
      - echo "Waiting for all processes to finish" && sleep 3s
      - task: perform-mapping
      - echo "Waiting for mapping to be finished" && sleep 5s
      - task: retrieve-additional-data
      - task: ingest-data-main
      - task: ingest-data-additional
      - task: cache-wikidata-thumbnails
      - task: retrieve-wikimedia-image-rights
      - task: ingest-ontologies
      - task: materialise-network
      - task: ingest-data-external
      - task: add-relations
      - task: clean-up
      - echo "Pipeline finished!"

  add-relations:
    desc: Materialise triples defined through the queries/addRelations.sparql query in the Blazegraph instance
    sources:
      - /data/ttl/main/*.ttl
      - /data/ttl/additional/*.ttl
      - /scripts/queries/addRelations.sparql
    cmds:
      - echo "Add relations"
      - task: _run-query-from-file
        vars: {FILE: "queries/addRelations.sparql"}

  cache-iiif-manifests:
    desc: Cache the IIIF manifests linked in the OAI XML records
    sources:
      - /data/xml/oai/*.xml
    generates:
      - /data/manifests/*.json
    cmds:
      - python /scripts/cacheIiifManifests.py --oaiXMLFolder /data/xml/oai --outputFolder /data/manifests {{.CLI_ARGS}}
  
  cache-thumbnails:
    silent: false
    interactive: True
    cmds:
      - python /scripts/cacheThumbnails.py --endpoint {{.ENDPOINT}} {{if .FILTER_CONDITION}}--filterCondition {{.FILTER_CONDITION}}{{end}} --propsFile {{.PROPS_FILE}} --outputDir {{.OUTPUT_DIR}} --namedGraph {{.NAMED_GRAPH}} --thumbnailLocation $HOST_LOCATION{{.HOST_PATH}}

  cache-wikidata-thumbnails:
    desc: Cache thumbnails of Wikidata entities
    sources:
      - /data/ttl/additional/wd.ttl
    generates:
      - /apps/static/assets/no_auth/thumbnail-*.jpg
    cmds:
      - task: cache-thumbnails
        vars:
          ENDPOINT: http://blazegraph:8080/blazegraph/sparql
          FILTER_CONDITION: wdt:P18
          HOST_PATH: /assets/no_auth
          OUTPUT_DIR: /apps/static/assets/no_auth
          NAMED_GRAPH: https://resource.jila.zb.uzh.ch/graph/thumbnails
          PROPS_FILE: /apps/jila/config/ui.prop

  clean-up:
    desc: Perform clean-up operations on data in triple store
    cmds:
      - echo "Clean up"
      - task: _run-query-from-file
        vars: {FILE: "queries/cleanup.sparql"}

  drop-graph:
    desc: Drops a named graph from the Blazegraph instance
    cmds:
      - curl --silent -X POST {{.BLAZEGRAPH_ENDPOINT}} --data-urlencode "update=DROP GRAPH <{{.GRAPH}}>" > /dev/null

  
  generate-example-record:
    desc: Generates an example record for developing the mapping in the X3ML editor
    cmds:
      - cat /data/xml/merged/9b570bfd545247fab57346996242c9fd.xml /data/xml/merged/b587c12ecb8b4a5fb9c1b7e075b9f8c0.xml /data/xml/merged/cdc330b211924b7dad51274f51831e18.xml /data/xml/merged/0c0583bb7ac742b08269229ac595be7b.xml /data/xml/merged/712bf7c61f594314b146f81bf6a01add.xml /data/xml/merged/87f585a3871a4f459da1d77cf3d8b2d5.xml /data/xml/merged/7a96e18b43c44899a85b906109775066.xml /data/xml/merged/43a2ab3eb18841db9ec1af3669b74f39.xml /data/xml/merged/1d8aa2259598424982799bce87ec3c86.xml /data/xml/merged/13ff406d0e7946fc90449c4061917c31.xml /data/xml/merged/43908e6998744707b9f97af7af418d61.xml > /mapping/example-record.xml
      - sed -i 's/<collection>//g' /mapping/example-record.xml
      - sed -i 's/<\/collection>//g' /mapping/example-record.xml
      - echo '<collection>' | cat - /mapping/example-record.xml > temp && mv temp /mapping/example-record.xml; echo '</collection>' >> /mapping/example-record.xml
  
  ingest-data-from-folder:
    desc: Ingests data from a specified folder. If a named graph is specified (GRAPH), TTL files will be ingested into it. Otherwise, the filename will be used as named graph. Named Graphs specified in Trig files will be used as defined
    cmds:
      - |
        numfiles=$(ls -l {{.FOLDER}}/* | egrep '.ttl|.trig' | wc -l)
        count=1
        {{if .GRAPH}}curl --silent -X POST {{.BLAZEGRAPH_ENDPOINT}} --data-urlencode "update=DROP GRAPH <{{.GRAPH}}>" > /dev/null{{end}}
        for f in $(ls -1 {{.FOLDER}}/* | grep .ttl); do
          echo "Ingesting file $count of $numfiles ($f)"
          curl --silent -X POST --data-binary "uri=file://$f" {{.BLAZEGRAPH_ENDPOINT}}?context-uri={{if .GRAPH}}{{.GRAPH}}{{else}}file://$f{{end}}
          count=$((count+1)) 
        done
        for f in $(ls -1 {{.FOLDER}}/* | grep .trig); do
          echo "Ingesting file $count of $numfiles ($f)"
          curl --silent -X POST --data-binary "uri=file://$f" {{.BLAZEGRAPH_ENDPOINT}}{{if .GRAPH}}?context-uri={{.GRAPH}}{{end}}
          count=$((count+1)) 
        done

  ingest-data-from-file:
    cmds:
      - echo "Ingest {{.NAME}}"
      - curl -X POST -H 'Content-Type:{{.TYPE}}' --data-binary '@{{.FILE}}' {{.BLAZEGRAPH_ENDPOINT}}{{if .GRAPH}}?context-uri={{.GRAPH}}{{end}}

  ingest-data-additional:
    desc: Ingest the TTL and Trig files located in the data/ttl/additional folder to the Blazegraph instance. 
    sources:
      - /data/ttl/additional/*.ttl
      - /data/ttl/additional/*.trig
    cmds:
      - echo "Ingest additional data"
      - task: drop-graph
        desc: Graphs that need to be overwritten are dropped
        vars:
          GRAPH: https://resource.jila.zb.uzh.ch/graph/network/labels
      - task: drop-graph
        vars:
          GRAPH: https://resource.jila.zb.uzh.ch/graph/network/vocab
      - task: ingest-data-from-folder
        vars: 
          FOLDER: /data/ttl/additional
          GRAPH: https://resource.jila.zb.uzh.ch/graph/external

  ingest-data-external:
    desc: Ingest data from external sources
    sources:
      - /data/external/*.*
    cmds:
      - echo "Ingest external data"
      - task: ingest-data-from-heidelberg
    
  ingest-data-from-heidelberg:
    sources:
      - /data/external/heidelberg.nq
    cmds:
      - task: ingest-data-from-file
        vars:
          BLAZEGRAPH_ENDPOINT: '{{.BLAZEGRAPH_ENDPOINT_SECONDARY}}'
          NAME: Heidelberg Werkverzeichnis
          FILE: /data/external/heidelberg.nq
          TYPE: application/n-quads

  ingest-data-main:
    desc: Ingest the TTL files located  in /data/ttl to the Blazegraph instance
    sources:
      - /data/ttl/main/*.ttl
    cmds:
      - echo "Ingest main data"
      - task: ingest-data-from-folder
        vars:
          FOLDER: /data/ttl/main
          GRAPH: https://resource.jila.zb.uzh.ch/graph/main
  
  ingest-ontologies:
    desc: Ingests the ontologies into individual named Graphs
    sources:
      - /mapping/schemas/CIDOC_CRM_7.1.1_RDFS_Impl_v1.1.rdfs
      - /mapping/schemas/CRMdig_v3.2.1.rdfs
    cmds:
      - task: ingest-data-from-file
        vars:
          NAME: CIDOC-CRM
          FILE: /mapping/schemas/CIDOC_CRM_7.1.1_RDFS_Impl_v1.1.rdfs
          TYPE: application/rdf+xml
          GRAPH: http://www.cidoc-crm.org/cidoc-crm/
      - task: ingest-data-from-file
        vars:
          NAME: CRMdig
          FILE: /mapping/schemas/CRMdig_v3.2.1.rdfs
          TYPE: application/rdf+xml
          GRAPH: http://www.ics.forth.gr/isl/CRMdig/

  materialise-network:
    desc: Materialises the relations used for the network visualisations
    sources:
      - /scripts/materialiseRelations.py
      - /scripts/definitions/network.yml
      - /data/ttl/main/*.ttl
      - /data/ttl/additional/gnd.ttl
      - /data/ttl/additional/networkLabels.trig
    vars:
      GRAPH: https://resource.jila.zb.uzh.ch/graph/network
    cmds:
      - python /scripts/materialiseRelations.py --endpoint {{.BLAZEGRAPH_ENDPOINT}} --graph {{.GRAPH}} --definitions /scripts/definitions/network.yml

  perform-mapping:
    desc: Map the input XML data to CIDOC/RDF
    vars:
      INPUT_FOLDER: /data/xml/merged
      OUTPUT_FOLDER: /data/ttl/main
      MAPPING_FILE: /mapping/mapping.x3ml
    sources:
      - /data/xml/merged/*.xml
      - /mapping/generator-policy.xml
      - /mapping/mapping.x3ml
    generates:
      - /data/ttl/main/*.ttl
    cmds:
      - rm -f {{.OUTPUT_FOLDER}}/*.ttl
      - bash /scripts/performMapping.sh -i {{.INPUT_FOLDER}} -o {{.OUTPUT_FOLDER}} -m {{.MAPPING_FILE}} -g {{.GENERATOR_POLICY}} -b {{.MAPPING_BATCH_SIZE}}
  
  prepare-data-for-mapping:
    desc: Prepare the source and OAI data for mapping. To include only a subset of the data, use the `--limit` option. To include only records with DOIs, use the `--onlyWithDoi` option. To only output specific records, use the `--idsToOutput` option providing a comma-separated list of IDs.
    interactive: True
    sources:
      - /scripts/prepareDataForMapping.py
      - /scripts/lib/utils.py
      - /scripts/lib/parser.py
      - /data/source/*.json
      - /data/source/*.csv
      - /data/xml/oai/*.xml
    generates:
      - /data/xml/merged/*.xml
    cmds:
      - rm -f /data/xml/merged/*.xml
      - python prepareDataForMapping.py --sourceFolder /data/source --manifestsFolder /data/manifests --oaiXMLFolder /data/xml/oai --outputFolder /data/xml/merged {{.CLI_ARGS}}
  
  retrieve-additional-data:
    desc: Retrieve additional reference data for the mapped data
    interactive: True
    sources:
      - /data/ttl/main/*.ttl
      - /scripts/retrieveAdditionalData.py
    cmds:
      - python retrieveAdditionalData.py --sourceFolder /data/ttl/main --targetFolder /data/ttl/additional --sources aat,gnd,wd,loc

  retrieve-data-from-e-manuscripta:
    desc: Retrieve the OAI records from from e-manuscripta
    interactive: True
    sources:
      - /script/retrieveDataFromEManuscripta.py
      - /data/source/*.json
    generates:
      - /data/xml/oai/*.xml
    cmds:
      - python retrieveDataFromEManuscripta.py --endpoint {{.OAI_ENDPOINT}} --inputFolder /data/source/ --outputFolder /data/xml/oai/

  retrieve-wikimedia-image-rights:
    desc: Retrieve the image rights metadata for the extracted images from Wikimedia Commons
    interactive: True
    sources:
      - /scripts/extractWikimediaImageRights.py
      - /data/ttl/additional/wd.ttl
    generates:
      - /data/ttl/additional/wdRights.ttl
    cmds:
      - python /scripts/extractWikimediaImageRights.py

  test-remarks-parser:
    desc: Parse remarks from a string and print the result
    cmds:
      - python /scripts/testParser.py --input {{.CLI_ARGS}}

  _run-query-from-file:
    silent: true
    vars:
      QUERY:
        sh: cat {{.FILE}}
    cmds:
      - curl -X POST {{.BLAZEGRAPH_ENDPOINT}} --data-urlencode "update={{.QUERY}}"